{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9829351535836177,
  "eval_steps": 100,
  "global_step": 72,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.027303754266211604,
      "grad_norm": 0.40302085876464844,
      "learning_rate": 0.0003,
      "loss": 3.1012,
      "step": 1
    },
    {
      "epoch": 0.05460750853242321,
      "grad_norm": 0.3570879101753235,
      "learning_rate": 0.000299853183977996,
      "loss": 3.0756,
      "step": 2
    },
    {
      "epoch": 0.08191126279863481,
      "grad_norm": 0.33317846059799194,
      "learning_rate": 0.0002994130233112417,
      "loss": 2.4891,
      "step": 3
    },
    {
      "epoch": 0.10921501706484642,
      "grad_norm": 0.32534751296043396,
      "learning_rate": 0.00029868037963491216,
      "loss": 2.8364,
      "step": 4
    },
    {
      "epoch": 0.13651877133105803,
      "grad_norm": 0.31042978167533875,
      "learning_rate": 0.0002976566871334088,
      "loss": 2.7711,
      "step": 5
    },
    {
      "epoch": 0.16382252559726962,
      "grad_norm": 0.3685534596443176,
      "learning_rate": 0.000296343949732876,
      "loss": 2.7931,
      "step": 6
    },
    {
      "epoch": 0.19112627986348124,
      "grad_norm": 0.3588918149471283,
      "learning_rate": 0.0002947447371784215,
      "loss": 2.89,
      "step": 7
    },
    {
      "epoch": 0.21843003412969283,
      "grad_norm": 0.4374997317790985,
      "learning_rate": 0.0002928621800037197,
      "loss": 2.5735,
      "step": 8
    },
    {
      "epoch": 0.24573378839590443,
      "grad_norm": 0.4115973114967346,
      "learning_rate": 0.0002906999634028451,
      "loss": 1.9531,
      "step": 9
    },
    {
      "epoch": 0.27303754266211605,
      "grad_norm": 0.48453062772750854,
      "learning_rate": 0.0002882623200163317,
      "loss": 2.3859,
      "step": 10
    },
    {
      "epoch": 0.3003412969283277,
      "grad_norm": 0.428619384765625,
      "learning_rate": 0.00028555402164558055,
      "loss": 2.3555,
      "step": 11
    },
    {
      "epoch": 0.32764505119453924,
      "grad_norm": 0.43324708938598633,
      "learning_rate": 0.0002825803699118341,
      "loss": 2.1184,
      "step": 12
    },
    {
      "epoch": 0.35494880546075086,
      "grad_norm": 0.4540207087993622,
      "learning_rate": 0.00027934718587800417,
      "loss": 2.6362,
      "step": 13
    },
    {
      "epoch": 0.3822525597269625,
      "grad_norm": 0.4744090139865875,
      "learning_rate": 0.0002758607986536673,
      "loss": 2.1578,
      "step": 14
    },
    {
      "epoch": 0.40955631399317405,
      "grad_norm": 0.368378609418869,
      "learning_rate": 0.00027212803300553614,
      "loss": 2.0324,
      "step": 15
    },
    {
      "epoch": 0.43686006825938567,
      "grad_norm": 0.45668646693229675,
      "learning_rate": 0.00026815619599765775,
      "loss": 2.7214,
      "step": 16
    },
    {
      "epoch": 0.4641638225255973,
      "grad_norm": 0.36335960030555725,
      "learning_rate": 0.0002639530626874927,
      "loss": 2.0962,
      "step": 17
    },
    {
      "epoch": 0.49146757679180886,
      "grad_norm": 0.42521584033966064,
      "learning_rate": 0.0002595268609058751,
      "loss": 3.0872,
      "step": 18
    },
    {
      "epoch": 0.5187713310580204,
      "grad_norm": 0.36255133152008057,
      "learning_rate": 0.0002548862551506471,
      "loss": 2.2755,
      "step": 19
    },
    {
      "epoch": 0.5460750853242321,
      "grad_norm": 0.3905092775821686,
      "learning_rate": 0.00025004032962549756,
      "loss": 2.5029,
      "step": 20
    },
    {
      "epoch": 0.5733788395904437,
      "grad_norm": 0.38235101103782654,
      "learning_rate": 0.00024499857045720704,
      "loss": 2.3927,
      "step": 21
    },
    {
      "epoch": 0.6006825938566553,
      "grad_norm": 0.3718753159046173,
      "learning_rate": 0.00023977084712610862,
      "loss": 2.0411,
      "step": 22
    },
    {
      "epoch": 0.6279863481228669,
      "grad_norm": 0.3600226044654846,
      "learning_rate": 0.0002343673931461171,
      "loss": 2.478,
      "step": 23
    },
    {
      "epoch": 0.6552901023890785,
      "grad_norm": 0.40501201152801514,
      "learning_rate": 0.00022879878603214478,
      "loss": 2.2117,
      "step": 24
    },
    {
      "epoch": 0.6825938566552902,
      "grad_norm": 0.4177909791469574,
      "learning_rate": 0.00022307592659411945,
      "loss": 2.3812,
      "step": 25
    },
    {
      "epoch": 0.7098976109215017,
      "grad_norm": 0.43626680970191956,
      "learning_rate": 0.00021721001759813675,
      "loss": 2.32,
      "step": 26
    },
    {
      "epoch": 0.7372013651877133,
      "grad_norm": 0.417507141828537,
      "learning_rate": 0.0002112125418365197,
      "loss": 2.0999,
      "step": 27
    },
    {
      "epoch": 0.764505119453925,
      "grad_norm": 0.4026862680912018,
      "learning_rate": 0.0002050952396497135,
      "loss": 2.384,
      "step": 28
    },
    {
      "epoch": 0.7918088737201365,
      "grad_norm": 0.423888623714447,
      "learning_rate": 0.00019887008594401763,
      "loss": 2.3277,
      "step": 29
    },
    {
      "epoch": 0.8191126279863481,
      "grad_norm": 0.4262716770172119,
      "learning_rate": 0.0001925492667501445,
      "loss": 3.1892,
      "step": 30
    },
    {
      "epoch": 0.8464163822525598,
      "grad_norm": 0.39651861786842346,
      "learning_rate": 0.00018614515536849213,
      "loss": 2.3121,
      "step": 31
    },
    {
      "epoch": 0.8737201365187713,
      "grad_norm": 0.4393640458583832,
      "learning_rate": 0.00017967028814782759,
      "loss": 1.9621,
      "step": 32
    },
    {
      "epoch": 0.9010238907849829,
      "grad_norm": 0.46495574712753296,
      "learning_rate": 0.00017313733994479531,
      "loss": 1.9976,
      "step": 33
    },
    {
      "epoch": 0.9283276450511946,
      "grad_norm": 0.37124887108802795,
      "learning_rate": 0.00016655909931229048,
      "loss": 2.6909,
      "step": 34
    },
    {
      "epoch": 0.9556313993174061,
      "grad_norm": 0.4044237434864044,
      "learning_rate": 0.00015994844346526557,
      "loss": 2.2978,
      "step": 35
    },
    {
      "epoch": 0.9829351535836177,
      "grad_norm": 0.4310134947299957,
      "learning_rate": 0.00015331831307297802,
      "loss": 1.8367,
      "step": 36
    },
    {
      "epoch": 1.0273037542662116,
      "grad_norm": 0.956395149230957,
      "learning_rate": 0.00014668168692702198,
      "loss": 4.8408,
      "step": 37
    },
    {
      "epoch": 1.0546075085324231,
      "grad_norm": 0.38219571113586426,
      "learning_rate": 0.00014005155653473443,
      "loss": 2.1376,
      "step": 38
    },
    {
      "epoch": 1.0819112627986347,
      "grad_norm": 0.4062900245189667,
      "learning_rate": 0.00013344090068770955,
      "loss": 2.2794,
      "step": 39
    },
    {
      "epoch": 1.1092150170648465,
      "grad_norm": 0.41063570976257324,
      "learning_rate": 0.0001268626600552046,
      "loss": 2.271,
      "step": 40
    },
    {
      "epoch": 1.136518771331058,
      "grad_norm": 0.4497949182987213,
      "learning_rate": 0.00012032971185217239,
      "loss": 2.4208,
      "step": 41
    },
    {
      "epoch": 1.1638225255972696,
      "grad_norm": 0.4162479341030121,
      "learning_rate": 0.00011385484463150784,
      "loss": 2.4901,
      "step": 42
    },
    {
      "epoch": 1.1911262798634812,
      "grad_norm": 0.4022113084793091,
      "learning_rate": 0.00010745073324985548,
      "loss": 1.9184,
      "step": 43
    },
    {
      "epoch": 1.2184300341296928,
      "grad_norm": 0.44384363293647766,
      "learning_rate": 0.00010112991405598238,
      "loss": 2.1699,
      "step": 44
    },
    {
      "epoch": 1.2457337883959045,
      "grad_norm": 0.4239364564418793,
      "learning_rate": 9.49047603502865e-05,
      "loss": 2.0234,
      "step": 45
    },
    {
      "epoch": 1.273037542662116,
      "grad_norm": 0.45402342081069946,
      "learning_rate": 8.878745816348025e-05,
      "loss": 2.1357,
      "step": 46
    },
    {
      "epoch": 1.3003412969283277,
      "grad_norm": 0.42001307010650635,
      "learning_rate": 8.278998240186322e-05,
      "loss": 1.8173,
      "step": 47
    },
    {
      "epoch": 1.3276450511945392,
      "grad_norm": 0.4411790668964386,
      "learning_rate": 7.692407340588055e-05,
      "loss": 2.0988,
      "step": 48
    },
    {
      "epoch": 1.3549488054607508,
      "grad_norm": 0.4303843080997467,
      "learning_rate": 7.12012139678552e-05,
      "loss": 2.1409,
      "step": 49
    },
    {
      "epoch": 1.3822525597269624,
      "grad_norm": 0.42485129833221436,
      "learning_rate": 6.56326068538829e-05,
      "loss": 1.862,
      "step": 50
    },
    {
      "epoch": 1.409556313993174,
      "grad_norm": 0.455280601978302,
      "learning_rate": 6.02291528738914e-05,
      "loss": 1.7869,
      "step": 51
    },
    {
      "epoch": 1.4368600682593857,
      "grad_norm": 0.4482582211494446,
      "learning_rate": 5.500142954279293e-05,
      "loss": 1.7551,
      "step": 52
    },
    {
      "epoch": 1.4641638225255973,
      "grad_norm": 0.40029722452163696,
      "learning_rate": 4.995967037450238e-05,
      "loss": 2.1575,
      "step": 53
    },
    {
      "epoch": 1.4914675767918089,
      "grad_norm": 0.4722962975502014,
      "learning_rate": 4.511374484935289e-05,
      "loss": 2.4657,
      "step": 54
    },
    {
      "epoch": 1.5187713310580204,
      "grad_norm": 0.42798513174057007,
      "learning_rate": 4.047313909412487e-05,
      "loss": 2.0535,
      "step": 55
    },
    {
      "epoch": 1.5460750853242322,
      "grad_norm": 0.438872367143631,
      "learning_rate": 3.604693731250729e-05,
      "loss": 1.9522,
      "step": 56
    },
    {
      "epoch": 1.5733788395904438,
      "grad_norm": 0.45513924956321716,
      "learning_rate": 3.1843804002342296e-05,
      "loss": 2.3388,
      "step": 57
    },
    {
      "epoch": 1.6006825938566553,
      "grad_norm": 0.40898460149765015,
      "learning_rate": 2.7871966994463884e-05,
      "loss": 2.1301,
      "step": 58
    },
    {
      "epoch": 1.627986348122867,
      "grad_norm": 0.4000401496887207,
      "learning_rate": 2.413920134633272e-05,
      "loss": 1.7246,
      "step": 59
    },
    {
      "epoch": 1.6552901023890785,
      "grad_norm": 0.44479021430015564,
      "learning_rate": 2.065281412199582e-05,
      "loss": 2.434,
      "step": 60
    },
    {
      "epoch": 1.68259385665529,
      "grad_norm": 0.48850756883621216,
      "learning_rate": 1.741963008816583e-05,
      "loss": 2.329,
      "step": 61
    },
    {
      "epoch": 1.7098976109215016,
      "grad_norm": 0.4529763162136078,
      "learning_rate": 1.4445978354419436e-05,
      "loss": 2.2875,
      "step": 62
    },
    {
      "epoch": 1.7372013651877132,
      "grad_norm": 0.47007033228874207,
      "learning_rate": 1.1737679983668258e-05,
      "loss": 2.0601,
      "step": 63
    },
    {
      "epoch": 1.764505119453925,
      "grad_norm": 0.4057522118091583,
      "learning_rate": 9.300036597154881e-06,
      "loss": 2.2535,
      "step": 64
    },
    {
      "epoch": 1.7918088737201365,
      "grad_norm": 0.4399407207965851,
      "learning_rate": 7.1378199962803025e-06,
      "loss": 2.6934,
      "step": 65
    },
    {
      "epoch": 1.819112627986348,
      "grad_norm": 0.49899882078170776,
      "learning_rate": 5.255262821578521e-06,
      "loss": 2.2811,
      "step": 66
    },
    {
      "epoch": 1.8464163822525599,
      "grad_norm": 0.464516282081604,
      "learning_rate": 3.6560502671239833e-06,
      "loss": 2.1892,
      "step": 67
    },
    {
      "epoch": 1.8737201365187715,
      "grad_norm": 0.4880066514015198,
      "learning_rate": 2.343312866591163e-06,
      "loss": 2.4834,
      "step": 68
    },
    {
      "epoch": 1.901023890784983,
      "grad_norm": 0.46590614318847656,
      "learning_rate": 1.3196203650878146e-06,
      "loss": 2.2755,
      "step": 69
    },
    {
      "epoch": 1.9283276450511946,
      "grad_norm": 0.42779749631881714,
      "learning_rate": 5.869766887582783e-07,
      "loss": 2.1852,
      "step": 70
    },
    {
      "epoch": 1.9556313993174061,
      "grad_norm": 0.45262232422828674,
      "learning_rate": 1.4681602200395936e-07,
      "loss": 1.9838,
      "step": 71
    },
    {
      "epoch": 1.9829351535836177,
      "grad_norm": 0.47718751430511475,
      "learning_rate": 0.0,
      "loss": 2.5874,
      "step": 72
    }
  ],
  "logging_steps": 1,
  "max_steps": 72,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 8.03408690722898e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}

This paper introduces shape-texture debiased training, a method that improves CNN performance by reducing bias toward shape or texture. It uses style-transferred images with conflicting cues, and assigns soft labels combining shape and texture information. The approach boosts accuracy and robustness across multiple benchmarks, including ImageNet, ImageNet-A/C, Stylized-ImageNet, and FGSM. It also generalizes to semantic segmentation and complements existing augmentation methods like CutMix and Mixup.
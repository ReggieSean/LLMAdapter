{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 15:18:42.147556: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703b52df1e0043678b46c0cbb69710df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b88ba88027d4602ac97cbcba513bf33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n",
    "from peft import PeftModel, PeftConfig\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# Load tokenizer\n",
    "model_name = \"meta-llama/Llama-3.2-3B-Instruct\"  # or the base model you trained on\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load base model in 4-bit if you used quantization\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "# manually set rope_scaling to supported structure:\n",
    "config.rope_scaling = {\"type\": \"dynamic\", \"factor\": 2.0}\n",
    "config.use_cache = True\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    "    config = config,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "adapted_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    "    config=config,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Load your LoRA adapter\n",
    "adapter_path = \"./../Training/final_adapter_with_eval_0\"  # or wherever your adapter_model.safetensors is\n",
    "adapted_model= PeftModel.from_pretrained(adapted_model, adapter_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to empty_cache other wise 2 models' results will bleed into each other\n",
    "# only slice and decode the new tokens \n",
    "def generate_summary(input_text, max_new_tokens=150):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    prompt = f\"\"\"Summarize:\\n{input_text} Summary:\\n\"\"\"\n",
    "\n",
    "#     prompt = f\"\"\"Without commentary, from its original language summarize to English on useful information including sensitive data, below 100 words. If no meaning return <NULL>\n",
    "# Text:\n",
    "# {input_text}\n",
    "\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(adapted_model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = adapted_model.generate(\n",
    "            **inputs,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            top_p=0.9\n",
    "        )\n",
    "    input_len = inputs[\"input_ids\"].shape[1]\n",
    "    new_tokens = outputs[0][input_len:]  # exclude prompt\n",
    "    summary = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "def generate_base_summary(input_text, max_new_tokens=150):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    prompt = f\"\"\"Summarize:\\n{input_text} Summary:\\n\"\"\"\n",
    "#     prompt = f\"\"\"Without commentary, from its original language summarize to English on useful information including sensitive data, below 100 words. If no meaning return <NULL>\n",
    "# Text:\n",
    "# {input_text}\n",
    "# \"\"\"\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(base_model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = base_model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9\n",
    "        )\n",
    "    input_len = inputs[\"input_ids\"].shape[1]\n",
    "    new_tokens = outputs[0][input_len:]  # exclude prompt\n",
    "    summary = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "    return summary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def get_json_from_file(file_path):\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = file.read().strip()\n",
    "\n",
    "        # Fix concatenated JSON objects\n",
    "        objs = data.split(\"}{\")\n",
    "\n",
    "        parsed_objs = []\n",
    "        for i, obj in enumerate(objs):\n",
    "            if not obj.startswith(\"{\"):\n",
    "                obj = \"{\" + obj\n",
    "            if not obj.endswith(\"}\"):\n",
    "                obj = obj + \"}\"\n",
    "            try:\n",
    "                parsed = json.loads(obj)\n",
    "                parsed_objs.append(parsed)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON in file {file_path}, object {i}: {e}\")\n",
    "    return parsed_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunks with formats 300\n",
      "chunks of recipts that need ocr 300\n",
      "chunks of well written long papers, no ocr 300\n",
      "chunks of all sorts 300\n",
      "chunks with filtered formats 99\n",
      "chunks with formatted receipts 100\n",
      "chunks with formatted reports 30\n",
      "chunks with formatted randoms 100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# example_file = \"./../Training/../Training/InputNLabel/prompt_sensitive_translated/receipts_2.json\"\n",
    "# file_and_limits = {\n",
    "#     \"./../Training/InputNLabel/filtered_labels/filtered_formatted.json\": 30,\n",
    "#     \"./../Training/InputNLabel/filtered_labels/filtered_randoms.json\": 30,\n",
    "#     \"./../Training/InputNLabel/filtered_labels/filtered_receipts.json\": 30,\n",
    "#     \"./../Training/InputNLabel/filtered_labels/filtered_reports.json\": 10,\n",
    "#     \"./../Training/InputNLabel/prompt_sensitive_translated/formatted_2.json\": 300,\n",
    "#     \"./../Training/InputNLabel/prompt_sensitive_translated/random_2.json\": 300,\n",
    "#     \"./../Training/InputNLabel/prompt_sensitive_translated/receipts_2.json\": 300,\n",
    "#     \"./../Training/InputNLabel/prompt_sensitive_translated/reports_2.json\": 300,\n",
    "# }\n",
    "formatted_chunks = \"./../Training/InputNLabel/prompt_sensitive_translated/formatted_2.json\"\n",
    "receipt_chunks = \"./../Training/InputNLabel/prompt_sensitive_translated/receipts_2.json\"\n",
    "report_chunks = \"./../Training/InputNLabel/prompt_sensitive_translated/reports_2.json\"\n",
    "random_chunks = \"./../Training/InputNLabel/prompt_sensitive_translated/random_2.json\"\n",
    "\n",
    "filtered_receipts = \"./../Training/InputNLabel/filtered_labels/filtered_receipts.json\"\n",
    "filtered_reports = \"./../Training/InputNLabel/filtered_labels/filtered_reports.json\"\n",
    "filtered_randoms = \"./../Training/InputNLabel/filtered_labels/filtered_randoms.json\"\n",
    "filtered_formatted = \"./../Training/InputNLabel/filtered_labels/filtered_formatted.json\"\n",
    "\n",
    "formatted = get_json_from_file(formatted_chunks)\n",
    "receipts = get_json_from_file(receipt_chunks)\n",
    "reports = get_json_from_file(report_chunks)\n",
    "randoms = get_json_from_file(random_chunks)\n",
    "\n",
    "f_receipts = get_json_from_file(filtered_receipts)\n",
    "f_reports = get_json_from_file(filtered_reports)\n",
    "f_randoms = get_json_from_file(filtered_randoms)\n",
    "f_formatted = get_json_from_file(filtered_formatted)\n",
    "\n",
    "print(\"chunks with formats\",len(formatted))\n",
    "print(\"chunks of recipts that need ocr\", len(receipts))\n",
    "print(\"chunks of well written long papers, no ocr\",len(reports))\n",
    "print(\"chunks of all sorts\",len(randoms))\n",
    "\n",
    "print(\"chunks with filtered formats\",len(f_formatted))\n",
    "print(\"chunks with formatted receipts\", len(f_receipts))\n",
    "print(\"chunks with formatted reports\", len(f_reports))\n",
    "print(\"chunks with formatted randoms\", len(f_randoms))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing filtered chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARKET\n",
      "Pesan as 62-2104\n",
      "se\n",
      "etna\n",
      "saa\n",
      "10h\n",
      "czy corn Eueees ‚Äù a\n",
      "Raurommcorse =|\n",
      "Aur isto.\n",
      "|| B\n",
      "ferecth a ne bibs\n",
      "B\n",
      "Stl\n",
      "a\n",
      "ate:\n",
      "f\n",
      "ital\n",
      "S\n",
      "Ei iam:\n",
      "paid\n",
      "Riles,\n",
      "ase\n",
      "1\n",
      "ip facoet mor\n",
      "his Er i Amn\n",
      "rug;\n",
      "AIT retro a e\n",
      "Wrveuty ov tee fc \n",
      "3B Ghar asia tea\n",
      "biti vat\n",
      "canter\n",
      "fc} tars ave a ele Taos\n",
      "a's Pras Stig, Vid tke\n",
      "{Sin ie a scon\n",
      "Tam 5 ack at ne fons e\n",
      "HR the tan Pres hoar\n",
      "(Shave a musi.cofet\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Output: <NULL>\n"
     ]
    }
   ],
   "source": [
    "input = f_receipts[0]\n",
    "print(input[\"input\"])\n",
    "print(\"\\nOutput:\",input[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!<---------Next Summary----------->!!!!\n",
      "Summary:\n",
      "<NULL>\n"
     ]
    }
   ],
   "source": [
    "input_text = input[\"input\"]\n",
    "#print(generate_base_summary(input_text,150))\n",
    "print(\"!!!!<---------Next Summary----------->!!!!\")\n",
    "print(generate_summary(input_text, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "<NULL>\n"
     ]
    }
   ],
   "source": [
    "print(f_reports[0][\"input\"])\n",
    "print(f_receipts[0][\"output\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Runs of trained adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!<----------------------->!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFC Nederland, located at KFC 'Jan van GaJen, Restaurant number 222, has a receipt (Chk 5460) for an order made on Oct09'19 at 06:58. The order includes 1 Upt 3 Hot Wings at EUR1.95, 1 Fire Stack Ch at EUR10.65, Pepsi Max - L at EUR0.65, and Fries at EUR0.65. The total payment was EUR12.60, paid by Master Card. The receipt also mentions a 9% VAT and a 2-minute wait. The customer is offered 3 free Hot Wings with their next order over EUR6. The receipt is closed at 18:58. Thank\n"
     ]
    }
   ],
   "source": [
    "input = receipts[0]\n",
    "#print(generate_base_summary(input[\"input\"]))\n",
    "print(\"!!!!<----------------------->!!!!\")\n",
    "print(generate_summary(input[\"input\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!<----------------------->!!!!\n",
      "!!!!<----------------------->!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: The Jack's New England Glam Chowder was shipped on August 11, 2017. The product was sold in a unit of 20, with each unit priced at 9.65. No further information is provided.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: The shipment took place on 2017-08-28. The products included were Gudbrandsdalsost with a quantity of 20 units at a unit price of 36.0, totaling 720.0, and Outback Lager with a quantity of 15 units at a unit price of 15.0, totaling 225.0. The overall total price was 945.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: Order ID 10481 was placed by Ricardo Adocicados (Customer ID: RICAR) from Av. Copacabana, 257, de Janeiro, Brazil on 2017-03-20 and shipped by United Package (Shipper ID: 2) on 2017-03-25. The order included 26 units of Maxiak at a unit price of 160. The order was handled by employee Laura Callahan. The shipping address is 02389-890, South America.\n",
      "The Jack's New England Glam Chowder was shipped on August 11, 2017. The product was sold in a unit of 20, with each unit priced at 9.65. The shipment took place on 2017-08-28. The products included were Gudbrandsdalsost with a quantity of 20 units at a unit price of 36.0, totaling 720.0, and Outback Lager with a quantity of 15 units at a unit price of 15.0, totaling 225.0. The overall total price was 945.0. Order ID 10481 was placed by Ricardo Adocicados (Customer ID: RICAR) from Av. Copacab\n"
     ]
    }
   ],
   "source": [
    "#trained adapter 0 after 72 examples: there is still original text but a summary is now  more concise\n",
    "input_text = formatted[0][\"input\"] + formatted[1][\"input\"] + formatted[2][\"input\"]\n",
    "\n",
    "#input_text = f_receipts[0][\"input\"]\n",
    "print(\"!!!!<----------------------->!!!!\")\n",
    "#print(generate_base_summary(input_text))\n",
    "print(\"!!!!<----------------------->!!!!\")\n",
    "summary_0 = generate_summary(formatted[0][\"input\"])\n",
    "print(\"0:\",summary_0)\n",
    "summary_1 = generate_summary(formatted[1][\"input\"])\n",
    "print(\"1:\",summary_1)\n",
    "summary_2 = generate_summary(formatted[2][\"input\"])\n",
    "print(\"2:\", summary_2)\n",
    "print(generate_summary(summary_0 + summary_1 + summary_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!<----------------------->!!!!\n",
      "The customer, Ricardo Adocicados, has placed an order for the following products:\n",
      "- Maxiak (26 units)\n",
      "- Gudbrandsdalsost (20 units)\n",
      "- Outback Lager (15 units)\n",
      "The order was shipped on March 25, 2017, from the United Package shipping company.\n",
      "The total price of the order is $945.00.\n",
      "The customer's shipping details are:\n",
      "- Ship Name: Ricardo Adocicados\n",
      "- Ship Address: Av. Copacabana, 257\n",
      "- Ship City: de Janeiro\n",
      "- Ship Postal Code: 02389-890\n",
      "- Ship County: Brazil\n",
      "- Ship Region: South America\n",
      "The customer's order details are:\n",
      "- Order Date:\n"
     ]
    }
   ],
   "source": [
    "print(\"!!!!<----------------------->!!!!\")\n",
    "print(generate_base_summary(input_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!<----------------------->!!!!\n",
      "The text is a shipping order from Ricardo Adocicados to United Package. The order was placed on 2017-03-20 and shipped on 2017-03-25. The order included two products: Maxiak with a quantity of 26 and unit price of 160.0, and Outback Lager with a quantity of 15 and unit price of 15.0. The total price was 945.0. The shipping details were sent to Ricardo Adocicados at Av. Copacabana, 257, Copacabana, de Janeiro, South America, 02389-890, Brazil. The order was handled by employee Laura Callahan and shipped by United Package.\n"
     ]
    }
   ],
   "source": [
    "print(\"!!!!<----------------------->!!!!\")\n",
    "print(generate_summary(input_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary  from one recursive pass of 3 summaries of original text \n",
    "\"\"\"The Jack's New England Glam Chowder was shipped on August 11, 2017. The product was sold in a unit of 20, with each unit priced at 9.65. The shipment took place on 2017-08-28. The products included were Gudbrandsdalsost with a quantity of 20 units at a unit price of 36.0, totaling 720.0, and Outback Lager with a quantity of 15 units at a unit price of 15.0, totaling 225.0. The overall total price was 945.0. Order ID 10481 was placed by Ricardo Adocicados (Customer ID: RICAR) from Av. Copacab\"\"\"\n",
    "\n",
    "#Summary  of adapted model from 1 pass of 3  chunks of original text \n",
    "\"\"\"The text is a shipping order from Ricardo Adocicados to United Package. The order was placed on 2017-03-20 and shipped on 2017-03-25. The order included two products: Maxiak with a quantity of 26 and unit price of 160.0, and Outback Lager with a quantity of 15 and unit price of 15.0. The total price was 945.0. The shipping details were sent to Ricardo Adocicados at Av. Copacabana, 257, Copacabana, de Janeiro, South America, 02389-890, Brazil. The order was handled by employee Laura Callahan and shipped by United Package.\"\"\"\n",
    "\n",
    "#Summary of base model from 3 chunks of original text\n",
    "\"\"\"\n",
    "The customer, Ricardo Adocicados, has placed an order for the following products:\n",
    "- Maxiak (26 units)\n",
    "- Gudbrandsdalsost (20 units)\n",
    "- Outback Lager (15 units)\n",
    "The order was shipped on March 25, 2017, from the United Package shipping company.\n",
    "The total price of the order is $945.00.\n",
    "The customer's shipping details are:\n",
    "- Ship Name: Ricardo Adocicados\n",
    "- Ship Address: Av. Copacabana, 257\n",
    "- Ship City: de Janeiro\n",
    "- Ship Postal Code: 02389-890\n",
    "- Ship County: Brazil\n",
    "- Ship Region: South America\n",
    "The customer's order details are:\n",
    "- Order Date:\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmlhw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
